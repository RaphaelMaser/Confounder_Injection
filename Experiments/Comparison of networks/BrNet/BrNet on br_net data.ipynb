{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "import Framework.Confounder_Injection as CI\n",
    "import Framework.Models as Models\n",
    "import importlib\n",
    "importlib.reload(Models)\n",
    "importlib.reload(CI)\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In \"Validation of synthetic data\" the case were the training_data was completely confounded was tested to show that neural networks indeed fit to confounding factors in images. Now the hypothesis is that if we have a small set of unconfounded data we can either use a confounder-free neural network or a DANN to unlearn the confounders. For establishing a performance baseline we need to test the SimpleConv on a dataset consisting of the confounded set and the small unconfounded set, otherwise the conditions would not be equal for the different networks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case there are 512 samples from the source domain (with correlating confounders) and a varying number of samples (16 or 64) from the target domain (with no confounders)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'Framework.Confounder_Injection' from '/home/raffi/Bachelor Arbeit/Jupyter/Confounder_Injection/Framework/Confounder_Injection.py'>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = Models.BrNet()\n",
    "batch_date = \"Thu Sep 29 15:20:59 CEST 2022\" # small validation set (8 samples)\n",
    "#batch_date = \"Thu Sep 29 18:46:13 CEST 2022\" # non-overlapping features\n",
    "#batch_date = \"Fri Sep 30 10:27:54 CEST 2022\" # test-data drawn from source domain broken\n",
    "#batch_date = \"Fri Sep 30 17:20:05 CEST 2022\" # fixed alpha and source domain as validation\n",
    "#batch_date = \"Tue Oct  4 11:16:19 CEST 2022\" # fixed alpha+weight decay and target domain as validation\n",
    "batch_date = \"Tue Oct  4 19:02:55 CEST 2022\" # fixed alpha and target domain as validation\n",
    "#batch_date = \"Wed Oct  5 09:54:26 CEST 2022\"\n",
    "batch_date = \"Tue Nov 15 13:53:26 CET 2022\" # fixed alpha and target domain as validation, 2k epochs\n",
    "batch_date =\"Tue Nov 15 21:28:23 CET 2022\" # fixed alpha and target domain as validation, 10k epochs\n",
    "\n",
    "# error fixed\n",
    "batch_date = \"Thu Nov 17 17:19:48 CET 2022\" # fixed alpha and target domain as validation,2k epochs\n",
    "batch_date = \"Thu Nov 17 21:30:26 CET 2022\" # fixed alpha and target domain as validation,10k epochs\n",
    "filters = {\n",
    "    \"config.batch_date\": batch_date,\n",
    "    # \"config.target_domain_samples\": 0,\n",
    "    # \"summary_metrics.confounder_strength\": 0,\n",
    "    # \"config.target_domain_confounding\":0,\n",
    "}\n",
    "importlib.reload(CI)\n",
    "#CI.wandb_sync.get_best_runs(project=\"Hyperparameters\", filters=filters, force_reload=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1.\n",
      "no-confounder\n",
      "0/512\n",
      "- summary_metrics.confounder_strength=0\n",
      "- config.target_domain_samples=0\n",
      "- config.target_domain_confounding=0\n",
      "- config.de_correlate_confounder_target=0\n",
      "- config.batch_date=Thu Nov 17 21:30:26 CET 2022\n",
      "- config.finetuning=0\n",
      "Searching for best runs ... 140 models found in database (20 models in each run)... done (30.028s)\n",
      "Re-creating models ... Skipped run: 8595117818875766427  ...  done (161.356s)\n",
      "Runs synced, models re-created and tested (took 195.376s)\n",
      "\n",
      "Experiment 2.\n",
      "no-confounder\n",
      "8/512\n",
      "- summary_metrics.confounder_strength=0\n",
      "- config.target_domain_samples=8\n",
      "- config.target_domain_confounding=0\n",
      "- config.de_correlate_confounder_target=0\n",
      "- config.batch_date=Thu Nov 17 21:30:26 CET 2022\n",
      "- config.finetuning=0\n",
      "Searching for best runs ... 140 models found in database (20 models in each run)... done (28.569s)\n",
      "Re-creating models ... Skipped run: 6921779499856680273  ...  Skipped run: 4400666087736321651  ...  Skipped run: 816043372290789393  ...  "
     ]
    }
   ],
   "source": [
    "importlib.reload(CI)\n",
    "table = CI.helper.BrNet_on_BrNet_data_all(batch_date=batch_date, force_reload=False, legacy=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(\"confounder_in_ml/Hyperparameters/12fn5hxk\")\n",
    "run.delete()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter(df, reverse=False):\n",
    "    if not reverse:\n",
    "        df = df[(df[\"model\"]==\"BrNet_DANN_entropy\")|(df[\"model\"]==\"BrNet\")|(df[\"model\"]==\"BrNet_DANN_corr\")|(df[\"model\"]==\"BrNet_CF_free_features_corr_conditioned_0.0\")|(df[\"model\"]==\"BrNet_CF_free_labels_entropy_conditioned_0.0\")|(df[\"model\"]==\"BrNet_CF_free_labels_entropy\")|(df[\"model\"]==\"BrNet_DANN_entropy_conditioned_0.0\")|(df[\"model\"]==\"BrNet_CF_free_features_corr\")|(df[\"model\"]==\"BrNet_CF_free_labels_corr\")]\n",
    "    else:\n",
    "        df = df[(df[\"model\"]!=\"BrNet_DANN_entropy\")&(df[\"model\"]!=\"BrNet\")&(df[\"model\"]!=\"BrNet_DANN_corr\")&(df[\"model\"]!=\"BrNet_CF_free_features_corr_conditioned_0.0\")&(df[\"model\"]!=\"BrNet_CF_free_labels_entropy_conditioned_0.0\")&(df[\"model\"]!=\"BrNet_CF_free_labels_entropy\")&(df[\"model\"]!=\"BrNet_DANN_entropy_conditioned_0.0\")&(df[\"model\"]!=\"BrNet_CF_free_features_corr\")&(df[\"model\"]!=\"BrNet_CF_free_labels_corr\")]\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.set_title(\"Accuracy\")\n",
    "CI.plot.plot_heatmap_with_mean(table[table[\"config.finetuning\"]==0], ax=ax, num=1, agg_func=np.mean, mean=True)\n",
    "ax.set_xlabel(\"experiments\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.set_title(\"Accuracy\")\n",
    "CI.plot.plot_heatmap_with_mean(table[table[\"config.finetuning\"]==0], ax=ax, num=1, agg_func=np.mean, mean=True, accuracy=\"confounder_accuracy\")\n",
    "ax.set_xlabel(\"experiments\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.set_title(\"Accuracy\")\n",
    "CI.plot.plot_heatmap_with_mean(table[table[\"config.finetuning\"]==0], ax=ax, num=5, agg_func=np.mean, mean=True)\n",
    "ax.set_xlabel(\"experiments\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.set_title(\"Accuracy\")\n",
    "CI.plot.plot_heatmap_with_mean(table[table[\"config.finetuning\"]==0], ax=ax, num=10, agg_func=np.var, mean=False)\n",
    "ax.set_xlabel(\"experiments\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table.pivot_table(index=\"model\", columns=\"experiment\", values=\"classification_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.set_title(\"Accuracy\")\n",
    "CI.plot.plot_heatmap_with_mean(table[table[\"config.finetuning\"]==1], ax=ax, num=1, agg_func=np.mean, mean=True)\n",
    "ax.set_xlabel(\"experiments\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(CI)\n",
    "# CI.plot.split_and_plot_heatmaps_with_mean(table)\n",
    "fig, ax = plt.subplots(1,1,figsize=(11,6))\n",
    "ax.set_title(\"Accuracy\")\n",
    "df = table\n",
    "#df = CI.plot.filter(table, filter_unrealistic=True)\n",
    "CI.plot.plot_heatmap_with_mean(df, ax=ax)\n",
    "ax.set_xlabel(\"experiments\")\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# No confounders in target data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 0 training-samples from target population"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=0, de_correlate_confounder_target=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 16 training-samples from target population"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy with more samples is the same but the network converges faster."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=16, de_correlate_confounder_target=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "config_filter = {\"confounder_strength\":1, \"target_domain_samples\":16, \"de_correlate_confounder_target\": False, \"batch_date\": date, \"target_domain_confounding\":0}\n",
    "p.accuracy_vs_epoch(file, config_filter, groupby=\"model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# De-correlated confounders in target- and test-data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 0 training-samples from target population\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=0, de_correlate_confounder_target=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 16 training-samples from target population"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=16, de_correlate_confounder_target=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 64 training-samples from target population"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=64, de_correlate_confounder_target=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "confounder_3.10",
   "language": "python",
   "display_name": "confounder_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
