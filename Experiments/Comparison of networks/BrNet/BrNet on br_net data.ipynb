{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "import Framework.Confounder_Injection as CI\n",
    "import Framework.Models as Models\n",
    "import importlib\n",
    "importlib.reload(Models)\n",
    "importlib.reload(CI)\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In \"Validation of synthetic data\" the case were the training_data was completely confounded was tested to show that neural networks indeed fit to confounding factors in images. Now the hypothesis is that if we have a small set of unconfounded data we can either use a confounder-free neural network or a DANN to unlearn the confounders. For establishing a performance baseline we need to test the SimpleConv on a dataset consisting of the confounded set and the small unconfounded set, otherwise the conditions would not be equal for the different networks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case there are 512 samples from the source domain (with correlating confounders) and a varying number of samples (16 or 64) from the target domain (with no confounders)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'Framework.Confounder_Injection' from '/home/raffi/Bachelor Arbeit/Jupyter/Confounder_Injection/Framework/Confounder_Injection.py'>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Models.BrNet()\n",
    "batch_date = \"Mon Sep 19 15:55:24 CEST 2022\"\n",
    "batch_date = \"Fri Sep 23 09:57:59 CEST 2022\"\n",
    "filters = {\n",
    "    \"config.batch_date\": batch_date,\n",
    "    # \"config.target_domain_samples\": 0,\n",
    "    # \"summary_metrics.confounder_strength\": 0,\n",
    "    # \"config.target_domain_confounding\":0,\n",
    "}\n",
    "importlib.reload(CI)\n",
    "# CI.wandb_sync.get_best_runs(project=\"Hyperparameters\", filters=filters, force_reload=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1.\n",
      "no-confounder\n",
      "0/512:\n",
      "-- batch_date=Mon Aug 29 14:10:50 CEST 2022\n",
      "-- test_confounding=0\n",
      "-- target_domain_samples=0\n",
      "-- target_domain_confounding=0\n",
      "-- de_correlate_confounder_target=0\n",
      "-- finetuning=0\n",
      "Searching for best runs ... 0\n",
      "0 models found in database ... done (0.602s)\n",
      "Re-creating models ... "
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/confounder_3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/anaconda3/envs/confounder_3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/confounder_3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'model_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m importlib\u001B[38;5;241m.\u001B[39mreload(CI)\n\u001B[0;32m----> 2\u001B[0m table \u001B[38;5;241m=\u001B[39m \u001B[43mCI\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhelper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBrNet_on_BrNet_data_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_date\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_reload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlegacy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m table\n",
      "File \u001B[0;32m~/Bachelor Arbeit/Jupyter/Confounder_Injection/Framework/Confounder_Injection.py:1479\u001B[0m, in \u001B[0;36mhelper.BrNet_on_BrNet_data_all\u001B[0;34m(batch_date, force_reload, seed, load_complete_model, legacy)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     experiments \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   1468\u001B[0m         helper\u001B[38;5;241m.\u001B[39mBrNet_on_BrNet_data(batch_date\u001B[38;5;241m=\u001B[39mbatch_date, test_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, target_domain_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, target_domain_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, de_correlate_confounder_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, force_reload\u001B[38;5;241m=\u001B[39mforce_reload, seed\u001B[38;5;241m=\u001B[39mseed, load_complete_model\u001B[38;5;241m=\u001B[39mload_complete_model, experiment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mno confounder\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m0/512\u001B[39m\u001B[38;5;124m\"\u001B[39m),\u001B[38;5;66;03m#1),\u001B[39;00m\n\u001B[1;32m   1469\u001B[0m         \u001B[38;5;66;03m#helper.BrNet_on_BrNet_data(batch_date=batch_date, test_confounding=1, target_domain_samples=0, target_domain_confounding=0, de_correlate_confounder_target=0, force_reload=force_reload, seed=seed, load_complete_model=load_complete_model, experiment=\"no-confounder\\n16/512\"),#2),\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1475\u001B[0m         helper\u001B[38;5;241m.\u001B[39mBrNet_on_BrNet_data(batch_date\u001B[38;5;241m=\u001B[39mbatch_date, test_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, target_domain_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, target_domain_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, de_correlate_confounder_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, force_reload\u001B[38;5;241m=\u001B[39mforce_reload, seed\u001B[38;5;241m=\u001B[39mseed, load_complete_model\u001B[38;5;241m=\u001B[39mload_complete_model, experiment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m5.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mde-correlated\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m64/512\u001B[39m\u001B[38;5;124m\"\u001B[39m),\u001B[38;5;66;03m#5),\u001B[39;00m\n\u001B[1;32m   1476\u001B[0m     ]\n\u001B[1;32m   1477\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1478\u001B[0m     experiments \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m-> 1479\u001B[0m         \u001B[43mhelper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBrNet_on_BrNet_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_date\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinetuning\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_confounding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_domain_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_domain_confounding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mde_correlate_confounder_target\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_reload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_reload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_complete_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_complete_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m1.\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mno-confounder\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m0/512\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m,\u001B[38;5;66;03m#1),\u001B[39;00m\n\u001B[1;32m   1480\u001B[0m         helper\u001B[38;5;241m.\u001B[39mBrNet_on_BrNet_data(batch_date\u001B[38;5;241m=\u001B[39mbatch_date, finetuning\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, test_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, target_domain_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, target_domain_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, de_correlate_confounder_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, force_reload\u001B[38;5;241m=\u001B[39mforce_reload, seed\u001B[38;5;241m=\u001B[39mseed, load_complete_model\u001B[38;5;241m=\u001B[39mload_complete_model, experiment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mno-confounder\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m16/512\u001B[39m\u001B[38;5;124m\"\u001B[39m),\u001B[38;5;66;03m#2),\u001B[39;00m\n\u001B[1;32m   1481\u001B[0m         helper\u001B[38;5;241m.\u001B[39mBrNet_on_BrNet_data(batch_date\u001B[38;5;241m=\u001B[39mbatch_date, finetuning\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, test_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, target_domain_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, target_domain_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, de_correlate_confounder_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, force_reload\u001B[38;5;241m=\u001B[39mforce_reload, seed\u001B[38;5;241m=\u001B[39mseed, load_complete_model\u001B[38;5;241m=\u001B[39mload_complete_model, experiment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mno-confounder\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m16/512\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfinetuning\u001B[39m\u001B[38;5;124m\"\u001B[39m),\u001B[38;5;66;03m#),\u001B[39;00m\n\u001B[1;32m   1482\u001B[0m \n\u001B[1;32m   1483\u001B[0m         helper\u001B[38;5;241m.\u001B[39mBrNet_on_BrNet_data(batch_date\u001B[38;5;241m=\u001B[39mbatch_date, finetuning\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, test_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, target_domain_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, target_domain_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, de_correlate_confounder_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, force_reload\u001B[38;5;241m=\u001B[39mforce_reload, seed\u001B[38;5;241m=\u001B[39mseed, load_complete_model\u001B[38;5;241m=\u001B[39mload_complete_model, experiment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m4.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mde-correlated\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m0/512\u001B[39m\u001B[38;5;124m\"\u001B[39m),\u001B[38;5;66;03m#4),\u001B[39;00m\n\u001B[1;32m   1484\u001B[0m         helper\u001B[38;5;241m.\u001B[39mBrNet_on_BrNet_data(batch_date\u001B[38;5;241m=\u001B[39mbatch_date, finetuning\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, test_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, target_domain_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, target_domain_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, de_correlate_confounder_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, force_reload\u001B[38;5;241m=\u001B[39mforce_reload, seed\u001B[38;5;241m=\u001B[39mseed, load_complete_model\u001B[38;5;241m=\u001B[39mload_complete_model, experiment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m5.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mde-correlated\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m16/512\u001B[39m\u001B[38;5;124m\"\u001B[39m),\u001B[38;5;66;03m#5),\u001B[39;00m\n\u001B[1;32m   1485\u001B[0m         helper\u001B[38;5;241m.\u001B[39mBrNet_on_BrNet_data(batch_date\u001B[38;5;241m=\u001B[39mbatch_date, finetuning\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, test_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, target_domain_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, target_domain_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, de_correlate_confounder_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, force_reload\u001B[38;5;241m=\u001B[39mforce_reload, seed\u001B[38;5;241m=\u001B[39mseed, load_complete_model\u001B[38;5;241m=\u001B[39mload_complete_model, experiment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m6.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mde-correlated\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m16/512\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfinetuning\u001B[39m\u001B[38;5;124m\"\u001B[39m),\u001B[38;5;66;03m#6),\u001B[39;00m\n\u001B[1;32m   1486\u001B[0m         helper\u001B[38;5;241m.\u001B[39mBrNet_on_BrNet_data(batch_date\u001B[38;5;241m=\u001B[39mbatch_date, finetuning\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, test_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, target_domain_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, target_domain_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, de_correlate_confounder_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, force_reload\u001B[38;5;241m=\u001B[39mforce_reload, seed\u001B[38;5;241m=\u001B[39mseed, load_complete_model\u001B[38;5;241m=\u001B[39mload_complete_model, experiment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m7.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mde-correlated\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m64/512\u001B[39m\u001B[38;5;124m\"\u001B[39m),\u001B[38;5;66;03m#7),\u001B[39;00m\n\u001B[1;32m   1487\u001B[0m         helper\u001B[38;5;241m.\u001B[39mBrNet_on_BrNet_data(batch_date\u001B[38;5;241m=\u001B[39mbatch_date, finetuning\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, test_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, target_domain_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, target_domain_confounding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, de_correlate_confounder_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, force_reload\u001B[38;5;241m=\u001B[39mforce_reload, seed\u001B[38;5;241m=\u001B[39mseed, load_complete_model\u001B[38;5;241m=\u001B[39mload_complete_model, experiment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m8.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mde-correlated\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m64/512\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfinetuning\u001B[39m\u001B[38;5;124m\"\u001B[39m),\u001B[38;5;66;03m#8),\u001B[39;00m\n\u001B[1;32m   1488\u001B[0m     ]\n\u001B[1;32m   1490\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(experiments)\n\u001B[1;32m   1491\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--- Synced and processed all experiments (took \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;241m-\u001B[39mt, \u001B[38;5;241m3\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms) ---\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Bachelor Arbeit/Jupyter/Confounder_Injection/Framework/Confounder_Injection.py:1460\u001B[0m, in \u001B[0;36mhelper.BrNet_on_BrNet_data\u001B[0;34m(batch_date, test_confounding, target_domain_samples, target_domain_confounding, de_correlate_confounder_target, force_reload, seed, load_complete_model, experiment, finetuning)\u001B[0m\n\u001B[1;32m   1457\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-- finetuning=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfinetuning\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1458\u001B[0m     filters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfig.finetuning\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m finetuning\n\u001B[0;32m-> 1460\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_best_networks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_reload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_reload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_complete_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_complete_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexperiment\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1461\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[0;32m~/Bachelor Arbeit/Jupyter/Confounder_Injection/Framework/Confounder_Injection.py:1288\u001B[0m, in \u001B[0;36mconfounder.test_best_networks\u001B[0;34m(self, project, filters, force_reload, load_complete_model, experiment)\u001B[0m\n\u001B[1;32m   1285\u001B[0m wandb_sync\u001B[38;5;241m.\u001B[39mget_best_runs(project\u001B[38;5;241m=\u001B[39mproject, filters\u001B[38;5;241m=\u001B[39mfilters, force_reload\u001B[38;5;241m=\u001B[39mforce_reload)\n\u001B[1;32m   1287\u001B[0m \u001B[38;5;66;03m# get models\u001B[39;00m\n\u001B[0;32m-> 1288\u001B[0m model_list \u001B[38;5;241m=\u001B[39m \u001B[43mwandb_sync\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_models_from_runs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproject\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproject\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_reload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_reload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_complete_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_complete_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1290\u001B[0m \u001B[38;5;66;03m# test networks and save accuracy\u001B[39;00m\n\u001B[1;32m   1291\u001B[0m results \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m:[], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassification_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m:[], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfounder_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m:[], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m\"\u001B[39m:[], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperiment\u001B[39m\u001B[38;5;124m\"\u001B[39m:[experiment \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(model_list))]}\n",
      "File \u001B[0;32m~/Bachelor Arbeit/Jupyter/Confounder_Injection/Framework/Confounder_Injection.py:411\u001B[0m, in \u001B[0;36mwandb_sync.create_models_from_runs\u001B[0;34m(project, filters, force_reload, load_complete_model)\u001B[0m\n\u001B[1;32m    407\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreate_models_from_runs: no best_results.pkl available\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    409\u001B[0m model_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 411\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m \u001B[43mruns\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m:\n\u001B[1;32m    412\u001B[0m     config \u001B[38;5;241m=\u001B[39m runs\u001B[38;5;241m.\u001B[39mloc[runs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_name\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m model]\n\u001B[1;32m    413\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mloc[:,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_class\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/confounder_3.10/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/anaconda3/envs/confounder_3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3623\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3624\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3625\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3626\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3627\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'model_name'"
     ]
    }
   ],
   "source": [
    "importlib.reload(CI)\n",
    "table = CI.helper.BrNet_on_BrNet_data_all(batch_date=batch_date, force_reload=True, legacy=False)\n",
    "table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter(df, reverse=False):\n",
    "    if not reverse:\n",
    "        df = df[(df[\"model\"]==\"BrNet_DANN_entropy\")|(df[\"model\"]==\"BrNet\")|(df[\"model\"]==\"BrNet_DANN_corr\")|(df[\"model\"]==\"BrNet_CF_free_features_corr_conditioned_0.0\")|(df[\"model\"]==\"BrNet_CF_free_labels_entropy_conditioned_0.0\")|(df[\"model\"]==\"BrNet_CF_free_labels_entropy\")|(df[\"model\"]==\"BrNet_DANN_entropy_conditioned_0.0\")|(df[\"model\"]==\"BrNet_CF_free_features_corr\")|(df[\"model\"]==\"BrNet_CF_free_labels_corr\")]\n",
    "    else:\n",
    "        df = df[(df[\"model\"]!=\"BrNet_DANN_entropy\")&(df[\"model\"]!=\"BrNet\")&(df[\"model\"]!=\"BrNet_DANN_corr\")&(df[\"model\"]!=\"BrNet_CF_free_features_corr_conditioned_0.0\")&(df[\"model\"]!=\"BrNet_CF_free_labels_entropy_conditioned_0.0\")&(df[\"model\"]!=\"BrNet_CF_free_labels_entropy\")&(df[\"model\"]!=\"BrNet_DANN_entropy_conditioned_0.0\")&(df[\"model\"]!=\"BrNet_CF_free_features_corr\")&(df[\"model\"]!=\"BrNet_CF_free_labels_corr\")]\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "CI.plot.plot_heatmap_with_mean(table, ax=ax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(CI)\n",
    "# CI.plot.split_and_plot_heatmaps_with_mean(table)\n",
    "fig, ax = plt.subplots(1,1,figsize=(11,6))\n",
    "ax.set_title(\"Accuracy\")\n",
    "df = table\n",
    "#df = CI.plot.filter(table, filter_unrealistic=True)\n",
    "CI.plot.plot_heatmap_with_mean(df, ax=ax)\n",
    "ax.set_xlabel(\"experiments\")\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# No confounders in target data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 0 training-samples from target population"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=0, de_correlate_confounder_target=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 16 training-samples from target population"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy with more samples is the same but the network converges faster."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=16, de_correlate_confounder_target=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "config_filter = {\"confounder_strength\":1, \"target_domain_samples\":16, \"de_correlate_confounder_target\": False, \"batch_date\": date, \"target_domain_confounding\":0}\n",
    "p.accuracy_vs_epoch(file, config_filter, groupby=\"model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# De-correlated confounders in target- and test-data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 0 training-samples from target population\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=0, de_correlate_confounder_target=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 16 training-samples from target population"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=16, de_correlate_confounder_target=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With 64 training-samples from target population"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CI.plot.split_and_plot_heatmaps(table, target_domain_samples=64, de_correlate_confounder_target=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
