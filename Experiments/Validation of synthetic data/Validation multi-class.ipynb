{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Framework.Confounder_Injection as CI\n",
    "import Framework.Models as Models\n",
    "import importlib\n",
    "importlib.reload(Models)\n",
    "importlib.reload(CI)\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Latex\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation with br_net data and multiple classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "batch_size = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## No confounder in training-data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case the network seems to learn to real feature. Adding confounder to the test-data leads to a lower accuracy (NN did not learn to handle this information). Nevertheless it is still able to recognize most of the classes. With higher number of epochs or samples this accuracy-loss might be prevented."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "params = [\n",
    "    [[1, 4], [3, 6], [5,8]], # real feature\n",
    "    [[10, 12], [20, 22], [30,32]] # confounder\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conditioning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m c \u001B[38;5;241m=\u001B[39m CI\u001B[38;5;241m.\u001B[39mconfounder()\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m Models\u001B[38;5;241m.\u001B[39mBr_Net(n_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbr-net\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_confounding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_confounding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1.01\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m l \u001B[38;5;241m=\u001B[39m c\u001B[38;5;241m.\u001B[39mtrain(model\u001B[38;5;241m=\u001B[39mmodel, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, optimizer\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam, hyper_params\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m0.001\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0\u001B[39m})\n",
      "File \u001B[0;32m~/Bachelor Arbeit/Jupyter/Confounder_Injection/Framework/Confounder_Injection.py:681\u001B[0m, in \u001B[0;36mconfounder.generate_data\u001B[0;34m(self, mode, overlap, samples, target_domain_samples, target_domain_confounding, train_confounding, test_confounding, de_correlate_confounder_test, de_correlate_confounder_target, params)\u001B[0m\n\u001B[1;32m    678\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m test_confounding\n\u001B[1;32m    680\u001B[0m \u001B[38;5;66;03m# train data\u001B[39;00m\n\u001B[0;32m--> 681\u001B[0m g_train \u001B[38;5;241m=\u001B[39m generator(mode\u001B[38;5;241m=\u001B[39mmode, samples\u001B[38;5;241m=\u001B[39msamples, overlap\u001B[38;5;241m=\u001B[39moverlap, confounding_factor\u001B[38;5;241m=\u001B[39mtrain_confounding, params\u001B[38;5;241m=\u001B[39mparams, domain\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, conditioning\u001B[38;5;241m=\u001B[39m\u001B[43mconditioning\u001B[49m)\n\u001B[1;32m    682\u001B[0m g_train_data \u001B[38;5;241m=\u001B[39m g_train\u001B[38;5;241m.\u001B[39mget_data()\n\u001B[1;32m    683\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_x[\u001B[38;5;241m0\u001B[39m,:samples\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes] \u001B[38;5;241m=\u001B[39m g_train_data[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'conditioning' is not defined"
     ]
    }
   ],
   "source": [
    "c = CI.confounder()\n",
    "model = Models.Br_Net(n_classes=3)\n",
    "c.generate_data(mode=\"br-net\", samples=512, train_confounding=0, test_confounding=np.arange(0, 1.01, 0.2), params=params)\n",
    "l = c.train(model=model, epochs=50, batch_size=batch_size, optimizer=torch.optim.Adam, hyper_params={'lr':0.001, \"weight_decay\": 0})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c.plot(accuracy_vs_strength=True, smoothgrad=True, saliency_iteration=[0,2], test_images=True, test_image_iteration=[0,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Confounder in training-data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Theoretical upper bound"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the network learns only the confounder we can define an upper bound for the accuracy. Let + be the event where the model determines the correct class and - the event where the model fails. c is the event in which an image is confounded. By the law of total probability it holds that:\n",
    "$$\n",
    "P(+) = P(+|c) * P(c) + P(+|\\neg{c}) * P(\\neg{c})\n",
    "$$\n",
    "\n",
    "Since $P(\\neg{c}) = 1- P(c)$ it further holds that:\n",
    "$$\n",
    "P(+|c) * P(c) + P(+|\\neg{c}) * P(\\neg{c}) = P(+|c) * P(c) + P(+|\\neg{c}) * (1 - P(c))\n",
    "$$\n",
    "Because the network only learns the confounder, there is a $ \\frac{1}{k} $ chance for guessing the outcome if no confounder is in the test data for k classes. If the confounder is seperable the network has a maximum probability of 1 for determining the correct class if a confounder is in the image. Therefore:\n",
    "$$\n",
    "P(+|\\neg{c}) = \\frac{1}{k}, \\\\P(+|c) = 1\n",
    "$$\n",
    "Putting these in (2) results in:\n",
    "$$\n",
    "1 * P(c) + \\frac{1}{k} * (1 - P(c))\n",
    "$$\n",
    "Therefore if the network learns only the confounder and the confounder is seperable, an upper bound, depending on $P(c)$, for k classes exists."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In both cases (3 and 5 classes) the network seems to only learn the confounder. If we vary P(c) in the test-set we can see that the accuracy of the network perfectly fits the theoretical upper bound. If the network learns the con"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = [\n",
    "    [[1, 4], [3, 6], [5,8]], # real feature\n",
    "    [[10, 12], [20, 22], [30,32]] # confounder\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c = CI.confounder()\n",
    "model = Models.Br_Net(n_classes=3)\n",
    "c.generate_data(mode=\"br-net\", samples=512, train_confounding=1, test_confounding=np.arange(0, 1.01, 0.05), params=params)\n",
    "l = c.train(model=model, epochs=50, batch_size=batch_size, optimizer=torch.optim.Adam, hyper_params={'lr':0.001, \"weight_decay\": 0})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c.plot(accuracy_vs_strength=True, smoothgrad=True, saliency_iteration=[0,2], test_images=True, test_image_iteration=[0,1], epoch_vs_strength_ideal=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = [\n",
    "    [[1, 4], [3, 6], [5, 8], [7, 10], [9, 12]], # real feature\n",
    "    [[10, 12], [13, 14], [16, 18], [19,20], [21, 22]] # confounder\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c = CI.confounder()\n",
    "model = Models.Br_Net(n_classes=5)\n",
    "c.generate_data(mode=\"br-net\", samples=512, train_confounding=1, test_confounding=np.arange(0, 1.01, 0.05), params=params)\n",
    "l = c.train(model=model, epochs=50, batch_size=batch_size, optimizer=torch.optim.Adam, hyper_params={'lr':0.001, \"weight_decay\": 0})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c.plot(accuracy_vs_strength=True, epoch_vs_strength_ideal=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}